{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import keras.backend\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "NUM_TRAIN = 2000\n",
    "NUM_VALID = 1000\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = cifar10.load_data()\n",
    "y2label = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "X_train = X_train[:NUM_TRAIN]\n",
    "y_train = y_train[:NUM_TRAIN]\n",
    "X_valid = X_valid[:NUM_VALID]\n",
    "y_valid = y_valid[:NUM_VALID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first few labelled images\n",
    "cols = 3\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(12, 8))\n",
    "plt.suptitle(\"Example labelled images\", fontsize=20)\n",
    "\n",
    "image_num = 0\n",
    "for row in range(rows): \n",
    "    for col in range(cols):\n",
    "        image_num += 1\n",
    "        ax[row][col].imshow(X_train[image_num], cmap='gray')\n",
    "        ax[row][col].set_title(\"Object: %s\" % y2label[y_train[image_num][0]])\n",
    "        ax[row][col].set_xticks([])\n",
    "        ax[row][col].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classification with standard neural network (from previous notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images to grayscale\n",
    "X_train_gray = X_train[:,:,:,0]*299/1000 + X_train[:,:,:,1]*587/1000 + X_train[:,:,:,2]*114/1000\n",
    "X_valid_gray = X_valid[:,:,:,0]*299/1000 + X_valid[:,:,:,1]*587/1000 + X_valid[:,:,:,2]*114/1000\n",
    "\n",
    "# preprocess images (make flat)\n",
    "num_pixels = X_train_gray.shape[1] * X_train_gray.shape[2]\n",
    "X_train_gray = X_train_gray.reshape(X_train_gray.shape[0], num_pixels).astype('float32')\n",
    "X_valid_gray = X_valid_gray.reshape(X_valid_gray.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# preprocess labels (make categorical)\n",
    "y_train_categorical = np_utils.to_categorical(y_train)\n",
    "y_valid_categorical = np_utils.to_categorical(y_valid)\n",
    "num_classes = y_valid_categorical.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train_gray, y_train_categorical, epochs=10, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = model.evaluate(X_valid_gray, y_valid_categorical, verbose=0)\n",
    "print('Test accuracy: {}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a Convolutional Neural Network (CNN)\n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(\n",
    "    Conv2D(\n",
    "            filters=32, \n",
    "            kernel_size=(5, 5), \n",
    "            strides=(1, 1),\n",
    "            activation='relu',\n",
    "            input_shape=(32, 32, 3)\n",
    "    )\n",
    ")\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                     strides=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(1000, activation='relu'))\n",
    "cnn.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural network prediction:\n",
    "<img src=\"images/CNN.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a deep convolutional neural network for `cifar10` image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-load data\n",
    "NUM_TRAIN = 10000\n",
    "NUM_VALID = 1000\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train[:NUM_TRAIN]\n",
    "y_train = y_train[:NUM_TRAIN]\n",
    "X_valid = X_valid[:NUM_VALID]\n",
    "y_valid = y_valid[:NUM_VALID]\n",
    "\n",
    "# re-preprocess images and labels\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "y_train_categorical = np_utils.to_categorical(y_train)\n",
    "y_valid_categorical = np_utils.to_categorical(y_valid)\n",
    "num_classes = y_valid_categorical.shape[1]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 strides=(1, 1),\n",
    "                 input_shape=(32, 32, 3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd_optimzer = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd_optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model persistence\n",
    "SKIP_TRAINING = True\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    # train model\n",
    "    model.fit(X_train, y_train_categorical, epochs=20, batch_size=64, verbose=1)\n",
    "    \n",
    "    # save model weights\n",
    "    model.save(\"cnn_weights.h5\")\n",
    "    already_trained = True\n",
    "    \n",
    "else:\n",
    "    # load model weights\n",
    "    model.load_weights(\"cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "scores = model.evaluate(X_valid, y_valid_categorical, verbose=0)\n",
    "print('Validation accuracy: {}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 9 trained filters in a given layer\n",
    "CHOOSE_LAYER = 0\n",
    "\n",
    "layer_weights_2d = model.layers[CHOOSE_LAYER].get_weights()[0][:,:,0,:]\n",
    "\n",
    "cols = 3\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(12, 8))\n",
    "fig.suptitle(\"Layer %i\" % CHOOSE_LAYER, fontsize=20)\n",
    "\n",
    "filter_num = 0\n",
    "for row in range(rows): \n",
    "    for col in range(cols):\n",
    "        ax[row][col].imshow(layer_weights_2d[:,:,filter_num],cmap=\"gray\")\n",
    "        ax[row][col].set_title(\"Filter %i\" % (filter_num+1), fontsize=12)\n",
    "        ax[row][col].set_yticks([])\n",
    "        ax[row][col].set_xticks([])\n",
    "        filter_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For an input image, visualize the first 9 filter activations in a given hiden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "CHOOSE_LAYER = 0\n",
    "CHOOSE_IMAGE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize image\n",
    "example_image = X_valid[CHOOSE_IMAGE]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(example_image)\n",
    "plt.title(\"True class: %s\" % y2label[y_valid[CHOOSE_IMAGE][0]], fontsize=20)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature maps for image in given hidden layer\n",
    "layer_fxn = backend.function(inputs=[model.input] + [backend.learning_phase()], \n",
    "                             outputs=[model.layers[CHOOSE_LAYER].output])\n",
    "layer_outputs = layer_fxn([example_image.reshape(1,32,32,3), 1])\n",
    "layer_activations = layer_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature maps\n",
    "cols = 3\n",
    "rows = 3\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(12,8))\n",
    "plt.suptitle(\"Activations in Layer %i\" % CHOOSE_LAYER, fontsize=20)\n",
    "filter_num = 0\n",
    "for row in range(0, rows): \n",
    "    for col in range(0, cols):\n",
    "        ax[row][col].imshow(layer_activations[0, :, :, filter_num], cmap='gray')\n",
    "        ax[row][col].set_title(\"Filter %i\" % (filter_num+1), fontsize=12)\n",
    "        ax[row][col].set_yticks([])\n",
    "        ax[row][col].set_xticks([])\n",
    "        filter_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict_classes(example_image.reshape(1,32,32,3))[0]\n",
    "print \"Predicted class: %s\" % y2label[y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a few predictions on validation set\n",
    "cols = 5\n",
    "rows = 5\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(15, 18))\n",
    "fig.suptitle(\"Predictions on validation data\", fontsize=20)\n",
    "\n",
    "image_num = 0\n",
    "for row in range(0, rows): \n",
    "    for col in range(0, cols):\n",
    "        y_true = y2label[y_valid[image_num][0]]\n",
    "        y_predicted = y2label[model.predict_classes(X_valid[image_num].reshape(1,32,32,3))[0]]\n",
    "        ax[row][col].imshow(X_valid[image_num])\n",
    "        title = \"True=%s\\nPredicted=%s\" % (y_true, y_predicted)\n",
    "        if y_true != y_predicted:\n",
    "            title += \" [X]\"\n",
    "        ax[row][col].set_title(title)\n",
    "        ax[row][col].set_yticks([])\n",
    "        ax[row][col].set_xticks([])\n",
    "        image_num += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: prediction on test data (challenge)\n",
    "\n",
    "We are going to ask our CNN model to classify images it has never seen before from an entirely different source:\n",
    "\n",
    "1. Download an example color image of each of the classes in `cifar10`. \n",
    "2. Use an image editor or code in Python (via `numpy`) to downsize these images to be 32 x 32 x 3. \n",
    "3. Feed each into the model you've created above for prediction via `predict_classes`.\n",
    "4. Evaluate how your model does.\n",
    "5. Diagnose your model by checking the first and last layer of activated feature maps for each image. Do the feature maps make sense?\n",
    "\n",
    "Based on how your model does, retrain your CNN to improve the **training**, **validation** and **test** accuracies. Experiment with different parameters:\n",
    "\n",
    "* Consider training on the *entire* `cifar10` dataset.\n",
    "* Increase the number of epochs.\n",
    "* Increase the training batch size.\n",
    "* Decrease the learning rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
